{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd94f0c-e22c-4bae-b01b-af95bff41767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tools/FINN2/notebooks/basics\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da62746-7bed-455c-a383-f7837abc8cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brevitas in /tools/FINN2/deps/brevitas/src (0.10.0)\n",
      "Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (2.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas) (24.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from brevitas) (68.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from brevitas) (1.13.3)\n",
      "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from brevitas) (4.12.2)\n",
      "Requirement already satisfied: unfoldNd in /tmp/home_dir/.local/lib/python3.10/site-packages (from brevitas) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->brevitas) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unfoldNd->brevitas) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " # Install brevitas first to get the earlier version of numpy\n",
    "!pip install brevitas\n",
    "import brevitas.nn as qn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "IMAGE_DEPTH = 64\n",
    "\n",
    "PROJECT_PATH = \"/tools/FINN2/Project/\"\n",
    "MODEL_PATH = PROJECT_PATH + \"Model/NonSquareConv2D_AE_2Stride_OutputQuantised_10_3_2025.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde927d1-3f61-4c94-b173-bb7306c59ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "from dependencies import value\n",
    "\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import FloatToIntImplType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.zero_point import ZeroZeroPoint\n",
    "from brevitas.inject import ExtendedInjector\n",
    "from brevitas.quant.solver import ActQuantSolver\n",
    "from brevitas.quant.solver import WeightQuantSolver\n",
    "\n",
    "\n",
    "class CommonQuant(ExtendedInjector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    zero_point_impl = ZeroZeroPoint\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND\n",
    "    scaling_per_output_channel = False\n",
    "    narrow_range = True\n",
    "    signed = True\n",
    "\n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width is None:\n",
    "            return QuantType.FP\n",
    "        elif bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT\n",
    "\n",
    "\n",
    "class CommonWeightQuant(CommonQuant, WeightQuantSolver):\n",
    "    scaling_const = 1.0\n",
    "\n",
    "\n",
    "class CommonActQuant(CommonQuant, ActQuantSolver):\n",
    "    min_val = -1.0\n",
    "    max_val = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be21ef52-b0be-4706-a255-7f550af828cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use non square conv2d\n",
    "\n",
    "BIT_WIDTH = 8\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            qn.QuantIdentity(act_quant=CommonActQuant, bit_width=BIT_WIDTH),\n",
    "            qn.QuantConv2d(11, 32, (3, 1),\n",
    "                           stride=(1, 1), padding=(1, 0),\n",
    "                           weight_bit_width=BIT_WIDTH,\n",
    "                           weight_quant=CommonWeightQuant,\n",
    "                           bias=False),\n",
    "            nn.MaxPool2d((2,1), stride=(2,1)),\n",
    "\n",
    "            qn.QuantIdentity(act_quant=CommonActQuant, bit_width=BIT_WIDTH),\n",
    "            qn.QuantConv2d(32, 64, (3, 1),\n",
    "                           stride=(1, 1), padding=(1, 0),\n",
    "                           weight_bit_width=BIT_WIDTH,\n",
    "                           weight_quant=CommonWeightQuant,\n",
    "                           bias=False),\n",
    "            nn.MaxPool2d((2,1), stride=(2,1)),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=(2,1)),\n",
    "            qn.QuantIdentity(act_quant=CommonActQuant, bit_width=BIT_WIDTH),\n",
    "            qn.QuantConv2d(64, 32, (3, 1),\n",
    "                           stride=1, padding=(1, 0),\n",
    "                           weight_quant=CommonWeightQuant,\n",
    "                           weight_bit_width=BIT_WIDTH,\n",
    "                           bias=False),\n",
    "            nn.Upsample(scale_factor=(2,1)),\n",
    "            qn.QuantIdentity(act_quant=CommonActQuant, bit_width=BIT_WIDTH),\n",
    "            qn.QuantConv2d(32, 11, (3, 1),\n",
    "                           stride=1, padding=(1, 0),\n",
    "                           weight_quant=CommonWeightQuant,\n",
    "                           weight_bit_width=BIT_WIDTH,\n",
    "                           bias=False),\n",
    "            qn.QuantIdentity(act_quant=CommonActQuant, bit_width=BIT_WIDTH),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49da1acd-e889-4b21-9c9b-9bf06910f113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoEncoder = AE().to(device)\n",
    "AutoEncoder.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f251a8-eac1-4da1-a26e-cf449df6098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoEncoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43db8bc9-9e0d-4038-8110-55dd6e10c6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1255: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
      "  return super(Tensor, self).rename(names)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 64, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inpt = torch.randn((1, 11, 64, 1))\n",
    "AutoEncoder(_inpt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad128268-df2f-4c04-bbb3-9af3b9fa8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "\n",
    "import onnx\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "\n",
    "from qonnx.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "\n",
    "BUILD_PATH = PROJECT_PATH + \"Build/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776d94c7-5fce-41b9-a99b-b967f0df4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "ONNX_PATH = PROJECT_PATH + \"ONNX/\"\n",
    "EXPORT_ONNX_PATH = ONNX_PATH + \"AutoEncoder_QONNX.onnx\"\n",
    "INPUT_SHAPE = (1, 11, 64, 1)\n",
    "\n",
    "export_qonnx(AutoEncoder, torch.randn(INPUT_SHAPE), EXPORT_ONNX_PATH);\n",
    "qonnx_cleanup(EXPORT_ONNX_PATH, out_file=EXPORT_ONNX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414317ca-1dcb-4097-a588-ac99a55ec23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tools/FINN2/Project/ONNX/AutoEncoder_QONNX.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dd3d92e00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(EXPORT_ONNX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0be3d3-b333-4976-9b15-4624c0f36dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(EXPORT_ONNX_PATH)\n",
    "\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "\n",
    "# print(model.check_all_tensor_shapes_specified(fix_missing_init_shape=True))\n",
    "# print(model.check_all_tensor_shapes_specified())\n",
    "# print(model.check_compatibility())\n",
    "\n",
    "model.save(BUILD_PATH + \"FINN_RAW.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30bf83ef-eadc-44a1-974c-c0959582e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "# model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "# model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "# model = model.transform(GiveReadableTensorNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a820036-49c8-4e4a-bd73-f6a430753834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build/FINN_RAW.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dd3d00a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"FINN_RAW.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b8a735-2eef-484c-b4fa-e5a5bc4944de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(BUILD_PATH + \"FINN_RAW.onnx\")\n",
    "\n",
    "# model = model.transform(Change3DTo4DTensors()) # Pre streamline for the conv1ds - https://github.com/Xilinx/finn/discussions/418\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(BUILD_PATH + \"FINN_1_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f47ac31-f4f3-44fc-a87a-d8fecab39a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build/FINN_1_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbbb71a80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"FINN_1_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a420750b-e47b-42ae-a302-ae80a5e959b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/FINN2/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "\n",
    "model = ModelWrapper(BUILD_PATH + \"FINN_1_tidy.onnx\")\n",
    "\n",
    "# model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(Streamline())\n",
    "\n",
    "model = model.transform(absorb.AbsorbTransposeIntoResize())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "\n",
    "# absorb final add-mul nodes into TopK\n",
    "# model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model.save(BUILD_PATH + \"FINN_2_Streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca14f1f-5185-491d-b9d6-b67dcc5107c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build/FINN_2_Streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dd3d008e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"FINN_2_Streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322692e-4aa8-4ff1-89bd-6efb8d205637",
   "metadata": {},
   "source": [
    "## *Conversion To Hardware*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c78805e-5182-4e6e-b3f8-970f0bc6cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# Using the Pynq-Z2 board\n",
    "pynq_board = \"Pynq-Z2\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10                           # Changed from 10 to 100\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "# from qonnx.transformation.resize_conv_to_deconv import ResizeConvolutionToDeconvolution\n",
    "# from finn.transformation.streamline.absorb import AbsorbTransposeIntoResize\n",
    "from finn.transformation.streamline.reorder import MoveTransposePastScalarMul\n",
    "\n",
    "from finn.transformation.streamline.collapse_repeated import CollapseRepeatedMul, CollapseRepeatedOp\n",
    "\n",
    "model = ModelWrapper(BUILD_PATH + \"FINN_2_Streamlined.onnx\")\n",
    "\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "# TopK to LabelSelect\n",
    "# model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "model = model.transform(to_hw.InferUpsample())           # <- Non square 2D upsampling not supported\n",
    "# get rid of Reshape(-1, 1) operation between hw nodes\n",
    "# model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# model = model.transform(ResizeConvolutionToDeconvolution())\n",
    "\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(MoveTransposePastScalarMul())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "# model = model.transform(CollapseRepeatedOp())\n",
    "model = model.transform(Streamline())\n",
    "\n",
    "\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "\n",
    "# Look at before partition\n",
    "# model.save(BUILD_PATH + \"temp.onnx\")\n",
    "# showInNetron(BUILD_PATH + \"temp.onnx\")\n",
    "\n",
    "\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(BUILD_PATH + \"FINN_3_ConversionToHardware_dataflow_parent.onnx\")\n",
    "\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "\n",
    "# node_types = [\"Thresholding\", \"FMPadding\", \"ConvolutionInputGenerator\", \"MVAU\", \"StreamingMaxPool\", \"UpsampleNearestNeighbour\"]\n",
    "# for node_type in node_types:\n",
    "#     nodes = dataflow_model.get_nodes_by_op_type(node_type)\n",
    "#     for node in nodes:\n",
    "#         node_inst = getCustomOp(node)\n",
    "#         node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "dataflow_model.save(BUILD_PATH + \"/FINN_3_ConversionToHardware_dataflow_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb5bcf3-ca32-4301-8e5d-815fdb9be2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build/FINN_3_ConversionToHardware_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbbb73bb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"FINN_3_ConversionToHardware_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2946e794-116b-4c3d-ac57-9ee696b93a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build//FINN_3_ConversionToHardware_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbbb710c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"/FINN_3_ConversionToHardware_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a289bdec-374d-4101-8b72-2f8ea451db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51befb57-e82c-497e-ad0c-467e7e4978f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(BUILD_PATH + \"FINN_3_ConversionToHardware_dataflow_model.onnx\")\n",
    "\n",
    "fc_layers = dataflow_model.get_nodes_by_op_type(\"MVAU_rtl\")\n",
    "\n",
    "# This caused overusage of hardware in PYNQ compilation stage\n",
    "# PE_SIMD_inFIFO = [\n",
    "#     (32,11,[128]),\n",
    "#     (64,32,[128]),\n",
    "#     (32,64,[128]),\n",
    "#     (11,32,[128])\n",
    "# ]\n",
    "\n",
    "PE_SIMD_inFIFO = [\n",
    "    (4,1,[8]),\n",
    "    (8,4,[8]), # We Want the most PE in the largest layer which is this one (64 filters) \n",
    "    (4,8,[8]),\n",
    "    (1,4,[8])\n",
    "]\n",
    "\n",
    "for layer, (PE, SIMD, inFIFO) in zip(fc_layers, PE_SIMD_inFIFO):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "\n",
    "    fcl_inst.set_nodeattr(\"PE\", PE)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", SIMD)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepths\", inFIFO)\n",
    "\n",
    "    \n",
    "\n",
    "# Need to set the output (PE) of the prev layer to the first MVAU to that MVAU's SIMD\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator_rtl\")\n",
    "for i in range(len(swg_layers)):\n",
    "    swg_inst = getCustomOp(swg_layers[i])\n",
    "    SIMD = PE_SIMD_inFIFO[i][1]\n",
    "    swg_inst.set_nodeattr(\"SIMD\", SIMD)\n",
    "\n",
    "dataflow_model.save(BUILD_PATH + \"/FINN_3_Post_PE_SIMD.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fbc2daa-8fd0-41df-890f-a8f4327cf4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build//FINN_3_Post_PE_SIMD.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbbb73ca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"/FINN_3_Post_PE_SIMD.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72acc5f5-db16-49da-bd67-455163bea42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/FINN2/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 34 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "/tools/FINN2/src/finn/transformation/fpgadataflow/insert_fifo.py:234: UserWarning: Input FIFO for IODMA_hls_0_out0 has depth 2 and won't\n",
      "                        be created. This may cause RTL simulation issues.\n",
      "                        \n",
      "  warnings.warn(\n",
      "/tools/FINN2/src/finn/transformation/fpgadataflow/insert_fifo.py:294: UserWarning: Output FIFO for MVAU_hls_0_out0 has depth 2 and won't\n",
      "                        be created. This may cause RTL simulation issues.\n",
      "                        \n",
      "  warnings.warn(\n",
      "/tools/FINN2/src/finn/transformation/fpgadataflow/create_stitched_ip.py:290: UserWarning: First node is not StreamingFIFO or IODMA.\n",
      "                You may experience incorrect stitched-IP rtlsim or hardware\n",
      "                behavior. It is strongly recommended to insert FIFOs prior to\n",
      "                calling CreateStitchedIP.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(BUILD_PATH + \"/FINN_3_Post_PE_SIMD.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd731cb8-ef12-40b7-970b-4ad3f1f50c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(BUILD_PATH + \"/FINN_3_POST_ZYNQ_BUILD.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1c15e26-874b-4bbf-bdcc-f43eb827e4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build//FINN_3_POST_ZYNQ_BUILD.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbba334f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"/FINN_3_POST_ZYNQ_BUILD.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1913af2-8218-46ff-8b41-7f20ca33d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.analysis.fpgadataflow.op_and_param_counts import op_and_param_counts\n",
    "from finn.analysis.fpgadataflow.post_synth_res import post_synth_res\n",
    "from finn.analysis.fpgadataflow.res_estimation import res_estimation_complete\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "# pp.pprint(mydict)\n",
    "\n",
    "model = ModelWrapper(getCustomOp(ModelWrapper(BUILD_PATH + \"/FINN_3_POST_ZYNQ_BUILD.onnx\").graph.node[1]).get_nodeattr(\"model\"))\n",
    "\n",
    "print(\"Dataflow Performance: \")\n",
    "pp.pprint(model.analysis(dataflow_performance))\n",
    "print(\"\")\n",
    "# print(\"HLS Resource Estimation\")\n",
    "# pp.pprint(model.analysis(hls_synth_res_estimation))\n",
    "print(\"\")\n",
    "print(\"OP and Param Counts:\")\n",
    "pp.pprint(model.analysis(op_and_param_counts))\n",
    "print(\"\")\n",
    "print(\"Estimates required resources for model\")\n",
    "pp.pprint(res_estimation_complete(model, pynq_board))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6dc98a1-305a-4f68-9067-6275e60e5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "model = ModelWrapper(BUILD_PATH + \"FINN_3_POST_ZYNQ_BUILD.onnx\")\n",
    "model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cff1fe9-d1bb-40c6-a424-69269ddeb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(BUILD_PATH + \"/FINN_3_PYNQ_DRIVER.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01f2d867-0e83-4f12-ae86-2f151e6d4e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/Build//FINN_3_PYNQ_DRIVER.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbba32830>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(BUILD_PATH + \"/FINN_3_PYNQ_DRIVER.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2196b7d-8448-495f-ad57-13aa3aa2b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tools/FINN2/Project/FINN_Build/dataflow_partition_9eyy7xa5/partition_2.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x771dbba332b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(BUILD_PATH + \"/FINN_3_PYNQ_DRIVER.onnx\")\n",
    "sdp_node_middle = getCustomOp(model.graph.node[1])\n",
    "postsynth_layers = sdp_node_middle.get_nodeattr(\"model\")\n",
    "\n",
    "showInNetron(postsynth_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c62219ec-cb28-496c-b379-bbab41d4bbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[key: \"floorplan_json\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vitis_floorplan_vuclmw5u/floorplan.json\"\n",
       ", key: \"vivado_stitch_proj\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vivado_stitch_proj_mwi_88pp\"\n",
       ", key: \"clk_ns\"\n",
       "value: \"10\"\n",
       ", key: \"wrapper_filename\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vivado_stitch_proj_mwi_88pp/finn_vivado_stitch_proj.gen/sources_1/bd/StreamingDataflowPartition_1/hdl/StreamingDataflowPartition_1_wrapper.v\"\n",
       ", key: \"vivado_stitch_vlnv\"\n",
       "value: \"xilinx_finn:finn:StreamingDataflowPartition_1:1.0\"\n",
       ", key: \"vivado_stitch_ifnames\"\n",
       "value: \"{\\\"clk\\\": [\\\"ap_clk\\\"], \\\"rst\\\": [\\\"ap_rst_n\\\"], \\\"s_axis\\\": [[\\\"s_axis_0\\\", 88]], \\\"m_axis\\\": [[\\\"m_axis_0\\\", 8]], \\\"aximm\\\": [], \\\"axilite\\\": []}\"\n",
       ", key: \"platform\"\n",
       "value: \"zynq-iodma\"\n",
       "]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(postsynth_layers)\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "025eb969-b074-45c8-b32f-3bd2131397f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[key: \"floorplan_json\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vitis_floorplan_vuclmw5u/floorplan.json\"\n",
       ", key: \"vivado_pynq_proj\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vivado_zynq_proj_jm3rm6rv\"\n",
       ", key: \"bitfile\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vivado_zynq_proj_jm3rm6rv/resizer.bit\"\n",
       ", key: \"hw_handoff\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vivado_zynq_proj_jm3rm6rv/resizer.hwh\"\n",
       ", key: \"vivado_synth_rpt\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/vivado_zynq_proj_jm3rm6rv/synth_report.xml\"\n",
       ", key: \"platform\"\n",
       "value: \"zynq-iodma\"\n",
       ", key: \"pynq_driver_dir\"\n",
       "value: \"/tools/FINN2/Project/FINN_Build/pynq_driver_dhs854le\"\n",
       "]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(BUILD_PATH + \"/FINN_3_PYNQ_DRIVER.onnx\")\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66239b-1aac-4830-aece-ce4d067c00b1",
   "metadata": {},
   "source": [
    "## PYNQ Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef323568-5d6c-4bdf-88d2-b8ab4ba4fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/driver_base.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/validate.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/qonnx/util/basic.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/qonnx/util/__init__.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/qonnx/core/datatype.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/qonnx/core/__init__.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/driver.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/finn/util/data_packing.py',\n",
       " '/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct/finn/util/__init__.py']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copy\n",
    "from distutils.dir_util import copy_tree\n",
    "from finn.util.basic import make_build_dir\n",
    "\n",
    "\n",
    "# create directory for deployment files\n",
    "deployment_dir = make_build_dir(prefix=\"pynq_deployment_\")\n",
    "model.set_metadata_prop(\"pynq_deployment_dir\", deployment_dir)\n",
    "\n",
    "# get and copy necessary files\n",
    "# .bit and .hwh file\n",
    "bitfile = model.get_metadata_prop(\"bitfile\")\n",
    "hwh_file = model.get_metadata_prop(\"hw_handoff\")\n",
    "deploy_files = [bitfile, hwh_file]\n",
    "\n",
    "for dfile in deploy_files:\n",
    "    if dfile is not None:\n",
    "        copy(dfile, deployment_dir)\n",
    "\n",
    "# driver.py and python libraries\n",
    "pynq_driver_dir = model.get_metadata_prop(\"pynq_driver_dir\")\n",
    "copy_tree(pynq_driver_dir, deployment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad8d25d6-ae61-45c2-a724-0c7d7784703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected network input shape is [1, 64, 1, 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(11, 64, 1).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "model = ModelWrapper(BUILD_PATH + \"/FINN_3_PYNQ_DRIVER.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "oname = parent_model.graph.output[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "print(\"Expected network input shape is \" + str(ishape))\n",
    "np.save(deployment_dir + \"/input.npy\", x.reshape(ishape).astype('int8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ec592a2-2cc5-4476-aefa-c9237c489e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tools/FINN2/Project/FINN_Build/pynq_deployment_189aqoct\n"
     ]
    }
   ],
   "source": [
    "! echo {deployment_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b2f1ad1-b2b8-4f99-a78a-e7f44b95a095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_base.py\tfinn\t   qonnx\tresizer.hwh\t validate.py\n",
      "driver.py\tinput.npy  resizer.bit\truntime_weights\n"
     ]
    }
   ],
   "source": [
    "! ls {deployment_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8a014a-f19e-49e9-863e-d66b406c5292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tools/FINN2/notebooks/basics/deploy-on-pynq-AutoEncoder.zip'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import make_archive\n",
    "make_archive('deploy-on-pynq-AutoEncoder', 'zip', deployment_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
